\documentclass[a4paper,12pt]{article}

\usepackage{url}
\usepackage{epsfig}
\usepackage{graphics}
\usepackage{fancyhdr}
\usepackage{breakcites}

\graphicspath{{pictures/}}

\title{Simultaneous Localization And Mapping in a domestic environment}
\author{\hspace*{-0.5cm}
\begin{tabular}{cccc}
Report Author &  Group Partner \\
Paul Rousse &  Jiaheng Qiu \\
\end{tabular}} 
\date{}

\pagestyle{fancy}
\fancyhf{}
\setlength{\headheight}{15pt}
\lhead{EL2320}
\rhead{$TODO$ \today}

\begin{document}

\maketitle
\thispagestyle{fancy}

\begin{abstract}

Many application of mobile robots take place in a domestic environment (cleaning robot, wheelchair). Localization and mapping are needed in order the robot know where he his. Scanning laser range sensor are most of the time too expensive to be used on these application, cameras have a high CPU cost and might be too sensitive to lighting conditions. We tried to work with ir range sensor because of a lower cost and the easy data acquisition.
An Extended Kalman Filter has been used to approximate the state of the robot and map features. As in most domestical environments, the map can be drawn with walls either parallel either  orthogonal.
We succefully implemented an algorithm that work on simulation
Unfortunately we did not have any real robot to check the algorithm on a real situation.


\end{abstract}
\clearpage

\section{Introduction}
The Silmutaneous Localization And Mapping problem (SLAM) has been one of the most active field of research in robotic the last 3 decade. 
In most application of mobile robot it is crucial to know the position of the robot in order to success in its task. However, a previous knowledge about the environment the robot evolve in is not always available. That is what the SLAM problem tries to solve: localizate the root while simultaneously build a map of the environment, and try to minimize errors.
~\cite{Whyte06} sum up most of the work on SLAM.

Many different algorithms for SLAM have been devlopped, mainly because the success of the algorithm depends on the sensors you have, the features on your map and the robot motion.
The laser range finder met a great success in the researcher community (\cite{jensfelt1999laser};\cite{diosi2005laser}%
%TODO citer plus%
).
The popularity of this sensor come fom the quality of the measure: "null" propagation time and fairly good range and angular accuracy.
%TODO developper%
However the expensive cost of this sensor make it not usable in an unprofessional mobile robot integration.
Cheaper sensors have been used such as sonar sensor (\cite{zunino2001simultaneous}; \cite{choi2008line}) or PSD infrared sensors (\cite{Abrate_experimentalekf-based}).

If ultrasonic sensors provide a better range estimate than PSD infrared sensors, they have a severe disadvantage: the time propagation is not negligeable when the distance measured id too far nor the robot speed too high. Therefore, the data are noisier and the fire rate is limited. The feature association  task become very hard. In order to get ride of this, \cite{zunino2001simultaneous} use an algorithm that can take advantages of geometrics constraints of an indoor environment in order to perform the classification step with only a few and noisy data: \textit{Triangulation Based Fusion} (\cite{wijk1998triangulation}). This method let to perform a SLAM localization with point features.
However this method is relevant only when the roboot cross a corner. And therefore, the estimation does not take care of the distance of the robot from the wall.

\cite{choi2005robust} has taken advantages of both point features and line features by combining the TBF method and an Extended Kalman Filter (EKF) implementation.
Later he adds some realistic constraints that can be met in an indoor environment.
\cite{choi2008line} tried to take in account this by measuring parameters of walls (angle and distance from the robot) and try to estimate them in a constrained EKF. Every measured point is stored and used in order to measure features of the map. As for \cite{nguyen2006orthogonal}, geometric constraints (such as parallel and orthogonal walls) add information to the map generation and in this way we can have a better estimation of localization and mapping.

\subsection{Contribution}
There are 3 main contributions in this article.
First an implementation of a SLAM algorithm with line-feature. Unlike point-feature SLAM implementation, line-feature have the disadvantages of being contiuous, therefore it is difficult to choose when we need to create a new feature or when we need to keep new points associated to the previous line-feature.
Second, we implemented a the constraint of parallel and orthogonal wall inside the EKF (not just in the measure of features).
Third, we show that a very simple algorithm can be used in order to create new features. In this way we avoid to use any Hough transform or heavy algorithm.

\subsection{Outline}

The first section will present a review of the previous workk. The second, the implementation of our SLAM algorithm: the state representation in the Extended Kalman Filter (EKF), the constrained model of the map and the feature addition. And the third part will focus on results and limitation of our algorithm.

\section{Related work}
\label{sec:relwork}

SLAM performed with sparse and noisy sensor based localization as been one of the challenges in domestic robot research. 
Most of researcher have used Hough transform in order to detect lines. If enough sensors was available, the line detection was be performed at each step (\cite{grossmann2001robust}), if just a few are available, the line detection is performed on a set of points measured on several steps.

That is the strategy of \cite{choi2008line} made an implementation of the SLAM algorithm in an indoor environment by using a smart pre-treamtment of all incoming measures from sonar sensors from the beginning of the mapping. This pre-treatment allow to reduce outlier generations and to perform an easier point-to-line association.
After this pre-treatment, line features are extracted thanks to a constrained Hough transform around mean angle of all line features. The EKF estimate each line featurse independently.
Therefore the constrained is set inside the measure and not inside the EKF.

The Hough transform used in \cite{choi2008line} is not a probabilistic tool, it is an approximation of a probabilistic tool (\cite{stephens1991probabilistic}).
Therefore, they developpe their own covariance calculation which does not take in account the uncertainty on measure.
This empirical method make the EKF difficult to adjust (the uncartainty on the measure does not affect the empirical covariance computation on the Hough transform!



\section{My method (1--4) pages}
\label{sec:method}

% Choix strategique
Most of the SLAM line-feature implemetation focus on measuring the line parameters  in the EKF. We have choosen to directly use the measures of sonars.
% Algorithm general
This choice was made in order to avoid implementing any Hough transform that will take too much computational ressources.


\subsection{Extended Kalman Filter}
\label{sec:EKF}

First, we will present the EKF method without any geometric constraints.
The EKF model is the same as \cite{zunino2001simultaneous} for the predict step: the state of the EKF is represented by the state of the robot $\mathbf{x_r} = \left [x_r,y_r,\theta_r \right ]^T$ followed by the $N_f$ state vectors of features.
The $i^{th}$ feature is represented just by its parameters in polar coordinates, $\mathbf{x_i} = [\rho_i, \theta_i]^T$.

The predict step does not affect covariance matrices of features because they are not part of the dynamics (they are just measurements).

The observation model compute the distance from the sensor to the $i^{th}$ wall feature in direction of the sensor. $\psi$ is the angle of the sensor in the reference of the robot and $d$ the sensor position along the robot.

\begin{equation}
h_i(\mathbf{x}) =\frac{ x_r \: cos \, \theta_i + y_r \: sin \, \theta_i - \rho_i + d\: cos(\theta_r-\theta_i)}{cos(\theta_i-\theta_r-\psi)} 
\end{equation}

%TODO schéma du robot!

% Qu'est-ce-que ça fait là!!!
The computation of the jacobian show that the farer the distance measured is, higher is the uncertainty (because in this way the angle of the impacted measure is very low and the uncertainties on angles $\theta_r$ and $\theta_i$ have more influence).
Therefore if we want to have a precise estimation of the wall we should have orthogonal measures from it. The most optimal way to set sensors is to set them al around the robot.

\subsection{Geometric constraints}
\label{sec:geom}

Geometrics constraints are both represented in the feature addition process and in the state vector of the EKF.
We added a state variable $\alpha$ that represent the global orientation of the map according to the initial robot position.

%TODO shéma de la map et de alpha

The state vector of the EKF become:

\begin{equation}
\mathbf{X} = 
\left [
\begin{array}{c}
\mathbf{x_r}\\ 
\alpha\\ 
\mathbf{x_1}\\
\vdots \\  
\mathbf{x_{N_f}}
\end{array}
\right ]
\end{equation}

We compute the observation model with the geometric constraint:

\begin{equation}
h_i(\mathbf{x}) =\frac{ x_r \: cos \, \beta_i(\alpha) + y_r \: sin \, \beta_i(\alpha) - \rho_i + d\: cos(\theta_r-\beta_i(\alpha))}{cos(\beta_i(\alpha)-\theta_r-\psi)} 
\end{equation}

with:

\begin{equation}
\begin{array}{l}
\beta_i(\alpha) = \alpha - k \: \frac{\pi}{2}\\
\mathit{with } \: k = \left \lfloor (\alpha-\theta_i) \: \frac{2 }{\pi} +\frac{1}{2} \right \rfloor
\end{array}
\end{equation}

In other words, $\beta_i$ is the closest angle from $\theta_i$ which verify $\alpha \equiv \beta_i \left [ \frac{\pi}{2} \right ]$.

In order to compute the jacobian matrix, we set:

\begin{equation}
\frac{\partial h}{\partial \alpha} = \frac{\partial h}{\partial \theta_i}
\end{equation}

with $i$ the observed feature.

\subsection{Features addition}
\label{sec:features}

After each execution of the EKF step, outliers are saved in a buffer of a fixed size $N_{buffer}$.
This buffer is used then to perform the line feature extraction.

%TODO Diagram of the algortihm

The clustering algorithm really depends on the number of sensors and how much the measures are noisy. If the measures are not so noisy and they are few sensors, then the classification can be performed just with sensor index (the measure is classified by the sensor it is coming from).
Otherwise a clustering algorithm is necessary: we used the DBSCAN discussed in \cite{ester1996density}.
This choice is not the optimal one, and we beleive that it is possible to choose a better one that take in account constraints and probability consideration (such as  probability distribution parameteeers of the hit point after a measure).
However, as long as data are not so noisy, the DBSCAN algorithm is enough.

In order to extract line feature of the dataset, we used the maximum of likelihood between vertical and horizontal line



% Why it can work (on attend qu'une tendance dde ligne se manifeste malgré le bruit

% Computation of a new features

% choice between vertical horizontal

% Sigma initialisation


\subsection{Implementation (0--2 pages)}

The description of your method should be provided at a level of
abstract where implementation details are avoided as much as
possible. For conveying general knowledge it is typically
uninteresting to know that you implemented your system in C++ or .NET
and that you make use of package so and so. However to assess your
results it may be important to know some of these details. This
section, if present, provides the implementation details. Limit the
description to what is important.  What language you used to implement
your system is in many cases not interesting either but it might be
interesting to know that you used a kd-tree to make access to certain
data more efficient or that you made this run super fast using the
GPU.  This is particularly important if you make comparisons of speed.
Comparing EKF in Matlab to PF using GPU it would be important to point
out theses details but if in the end you are focused on accuracy then
it does not matter at all.

Exactly what you put here varies from case to case. Instructions for
how to run your system would not end up here unless it is related to
the problem you deal with. Remember that it is not a software manual
or a user guide.

\section{Experimental results (1--4 pages)}
\label{sec:exps}

In this project your task is to create a working implementation of some estimation method so an experimental evaluation is to be expected. Make
experiments that backs up the claims you make. If you have improved /
modified some other method, compare your new method with the old. If
possible include other methods in the comparison.

Here you should have figures and tables that show the results.  It is
best if there are numerical measures such as mean square error or a
histogram over errors.  this is even better if the errors are
normalized with the covariance.  Often one plots the errors over time
as bars or points and the 2 sigma bound as a curve.  A figure that one
can see that the estimate is following the true values is good if you
can show it.  All that requires ground truth so if you do not have
that your job here is more difficult be creative and show something
that indicates it works.  For example the innovation process can still
be shown.

When writing a paper in a well researched area you would be expected
to compare your result to all or a significant fraction of related
results and show why your method / contribution is worth publication.
This does not apply here but some comparisons will help.

Make sure to provide your experimental setup carefully. You want
someone else to be able to replicate what you did.

A paper where everything works flawless according to the experiments
is typically looked upon with skepticism. Nothing is perfect! If you
get perfect results it often means that your tests where not
challenging enough. As a reader I want to know what the limitations
are so push it to the limit or at least provide solid arguments for
where such limits might be.

It is essential to provide an analysis of your results. It is not the
reader, but you, that should interpret the results. Do not assume that
the reader is an expert so even result that to you seem obvious may be
worth to point out. When you write a longer report, your thesis for
example, the warning lights should go off when you end up with figures
without any texts on several pages. In this case you have probably not
provided enough analysis.

As already said but worth repeating, all figures that you have in the
report must be referenced in the text. Provide captions that allows a
reader to browse your paper and get the gist of your
results. Summarize your findings at the end of each experiment if
long.

If you have statement / hypotheses that you cannot really back up with
the results put these at the end. Here you can speculate a bit and be
less formal.  But be clear that this is not a claim but speculation.

\section{Summary and Conclusions (0.5--1 page)}
\label{sec:summary}

Summarize what you have done and make sure that your highlight your
contributions. You should not introduce new results in the
summary. Results should be introduced in the main sections above. Here
you can speculate on how these results could be extended, what would
happen in other settings or how the method could be used other domains
and how to continue with the research in the future. In this section
you can put statements that one cannot understand unless you have read
the paper which is not possible in the abstract for example. You do
not need to be as formal in this section.



\bibliographystyle{apalike}
\bibliography{refs}


\end{document}
